{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28d9461-6238-483c-9dae-9f8fb6fe5080",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "- The process of selecting a subset of relevant features for use in model construction\n",
    "- Is different from dimensionality reduction. Both methods seek to reduce the number of attributes in the dataset, but a dimensionality reduction method do so by creating new combinations of attributes, where as feature selection methods include and exclude attributes present in the data without changing them.\n",
    "-  Used to identify and remove unneeded, irrelevant and redundant attributes from data that do not contribute to the accuracy of a predictive model or may in fact decrease the accuracy of the model.\n",
    "\n",
    "- **OBJECTIVES**: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965c7a10-1bc8-4add-80a8-1716626be3e5",
   "metadata": {},
   "source": [
    "![alt text](Feature_Selection_Techniques.png)\n",
    "\n",
    "*https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f0a73-debf-4101-a61d-e17ccc0a2e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42b8ab6c-49aa-4279-b97b-b64315fcf9d9",
   "metadata": {},
   "source": [
    "# Assumptions: \n",
    "\n",
    "- All the string features haven already been transformed to numeric ones (OneHotEncoder, OrdinalEncoder).\n",
    "- The data has been scaled (StandardScaler).\n",
    "- There are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce6e97-9222-4a87-9fe3-f19313e0b94e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87072cb6-963f-4e14-9731-1fb43895b3c1",
   "metadata": {},
   "source": [
    "# Imports, Parameters, and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc05457-ae0f-4c4a-a352-e8d1fea8d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed8ac5a5-b8eb-4717-92f1-8cadb10ed788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will do this just once to create the json file\n",
    "#df1 = pd.read_csv('../Data/titanic_train.csv')\n",
    "#df1.to_json(r'../Data/titanic_train.json')\n",
    "#df2 = pd.read_csv('../Data/titanic_test.csv')\n",
    "#df2.to_json(r'../Data/titanic_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d955642e-7af7-41e7-84e7-8a5e13882b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification (1) or Regression (0)\n",
    "classification_problem = 1\n",
    "\n",
    "# Define the name of the target column\n",
    "target = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "103c59d2-4141-4bdd-b602-fcae5a51e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(coeff, threshold):\n",
    "    cols = []\n",
    "    for i in range(len(coeff)):\n",
    "        value = coeff.iloc[i,0]\n",
    "        if (value > threshold):\n",
    "            cols.append(coeff.index[i])\n",
    "            \n",
    "    return(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde9f7f3-af3e-456d-a6d0-4845a0099194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70cf76de-4871-4e8b-8f32-8177834dc81d",
   "metadata": {},
   "source": [
    "# Load the data -> Faltando: Ler arquivo JSON com o dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f080130-546e-43e1-854f-fb92b894f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../Data/titanic_train.csv')\n",
    "df = pd.read_json('../Data/titanic_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ca336b-7851-4141-8eab-df89eb7c662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove observations with missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e9c2eec-18af-4c95-a778-47cab6fc30fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "1            2         1       1   \n",
       "3            4         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "\n",
       "   Parch    Ticket     Fare Cabin Embarked  \n",
       "1      0  PC 17599  71.2833   C85        C  \n",
       "3      0    113803  53.1000  C123        S  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca2742c-614e-4760-87db-dad9ab7f087c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3fcafd8-dbbc-454e-8557-1ffdd377a6e3",
   "metadata": {},
   "source": [
    "## Split the features from the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03de4850-1af6-4812-996b-0d45e8addc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(target, axis = 1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f025c52e-7481-4537-916d-52d4e129a85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 183 entries, 1 to 889\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  183 non-null    int64  \n",
      " 1   Pclass       183 non-null    int64  \n",
      " 2   Name         183 non-null    object \n",
      " 3   Sex          183 non-null    object \n",
      " 4   Age          183 non-null    float64\n",
      " 5   SibSp        183 non-null    int64  \n",
      " 6   Parch        183 non-null    int64  \n",
      " 7   Ticket       183 non-null    object \n",
      " 8   Fare         183 non-null    float64\n",
      " 9   Cabin        183 non-null    object \n",
      " 10  Embarked     183 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 17.2+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4886da1-3c10-4958-bb3b-05060957fa90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     1\n",
       "3     1\n",
       "6     0\n",
       "10    1\n",
       "11    1\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cfc4012-065b-46d4-961f-9bc0da05f5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     Y\n",
       "3     Y\n",
       "6     N\n",
       "10    Y\n",
       "11    Y\n",
       "Name: Survived, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a categorical target just to simulate this kind of output\n",
    "y_cat = y.apply(lambda x: 'N' if (x==0) else 'Y')\n",
    "y_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d0532-6e2f-4a9c-9b3b-b25395ed72c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecb77cd8-7688-4421-82f7-9610ba3caf4c",
   "metadata": {},
   "source": [
    "## Split Numerical and Categorical Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cf26f31-b7f3-49f8-8b9a-fec7105ba5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X.select_dtypes(include=[np.number])\n",
    "X_cat = X.select_dtypes(exclude=[np.number])\n",
    "\n",
    "df_num = df.select_dtypes(include=[np.number])\n",
    "df_cat = df.select_dtypes(exclude=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bc74ad5-d33e-4101-a7da-77708958bada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 183 entries, 1 to 889\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  183 non-null    int64  \n",
      " 1   Pclass       183 non-null    int64  \n",
      " 2   Age          183 non-null    float64\n",
      " 3   SibSp        183 non-null    int64  \n",
      " 4   Parch        183 non-null    int64  \n",
      " 5   Fare         183 non-null    float64\n",
      "dtypes: float64(2), int64(4)\n",
      "memory usage: 10.0 KB\n"
     ]
    }
   ],
   "source": [
    "X_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee320cae-1c11-41d8-9d72-e1a40dbecaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 183 entries, 1 to 889\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Name      183 non-null    object\n",
      " 1   Sex       183 non-null    object\n",
      " 2   Ticket    183 non-null    object\n",
      " 3   Cabin     183 non-null    object\n",
      " 4   Embarked  183 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 8.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X_cat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62b2a6ef-791c-4e5d-be02-40f649103cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 6)\n",
      "(183,)\n"
     ]
    }
   ],
   "source": [
    "print(X_num.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c47a1f-4bdb-49eb-b428-255875137ceb",
   "metadata": {},
   "source": [
    "# Feature Selection Algorithms: Filter, Wrapper and Intrinsic Methods\n",
    "\n",
    "https://machinelearningmastery.com/an-introduction-to-feature-selection/\n",
    "\n",
    "https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/\n",
    "\n",
    "https://machinelearningmastery.com/feature-selection-machine-learning-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9796ff-f60f-4826-b768-30d44b1a873a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aacfaac2-b818-4238-a0c3-ca2de13aad67",
   "metadata": {},
   "source": [
    "## Filter:\n",
    "\n",
    "- Methods apply a statistical measure to assign a scoring to each feature. The features are ranked by the score and either selected to be kept or removed from the dataset. \n",
    "- Methods: Information Gain, Pearson’s Correlation, Spearman’s Correlation, Feature Importance, Kendall's Tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3af76c-ae82-4879-9cb7-bd7a0f803d47",
   "metadata": {},
   "source": [
    "**Some univariate statistical measures that can be used for FILTER-based feature selection.**\n",
    "![alt text](Filter_Based_Feature_Selection.png)\n",
    "\n",
    "*https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea47057-4812-45af-8c33-57d2bb00a317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67130509-d8de-474b-9d8e-dff1cf2e8cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99b76ad7-af17-401d-8883-e4f273aa0c5e",
   "metadata": {},
   "source": [
    "### Numerical Input, Numerical Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8073f11b-eabc-4ece-b309-0ac3673c8a09",
   "metadata": {},
   "source": [
    "#### Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "896daa7c-9d5d-46f1-a7a2-deae7d6d6517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain\n",
      "             Coefficient\n",
      "PassengerId     0.000000\n",
      "Pclass          0.000000\n",
      "Age             0.070762\n",
      "SibSp           0.036635\n",
      "Parch           0.020543\n",
      "Fare            0.076065\n",
      "\n",
      "Columns to remain in the DF:  ['Age', 'SibSp', 'Parch', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Define the threshold\n",
    "threshold_IG = 0.02\n",
    "\n",
    "# Calculate the mutual information coefficients and convert them to a data frame\n",
    "coeff_IG =pd.DataFrame(mutual_info_classif(X_num, y).reshape(-1, 1),\n",
    "                         columns=['Coefficient'], index=X_num.columns)\n",
    "\n",
    "print('Information Gain')\n",
    "print(coeff_IG)\n",
    "\n",
    "# Only keep columns whose information gain is higer than the threshold\n",
    "cols_IG = select_columns(coeff_IG, threshold_IG) \n",
    "\n",
    "print('\\nColumns to remain in the DF: ', cols_IG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd168c12-9bf8-4677-a9ca-f413939f18f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "508d43a9-b4ec-46b3-a334-178b76530de5",
   "metadata": {},
   "source": [
    "#### Pearson's Correlation (Linear Correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "012ff268-2913-4b9c-96c4-4ff2afea102b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsons Correlation\n",
      "             Coefficient\n",
      "PassengerId     0.148495\n",
      "Fare            0.134241\n",
      "SibSp           0.106346\n",
      "Parch           0.023582\n",
      "Pclass          0.034542\n",
      "Age             0.254085\n",
      "\n",
      "Columns to remain in the DF:  ['PassengerId', 'Fare', 'SibSp', 'Age']\n"
     ]
    }
   ],
   "source": [
    "# Define the threshold \n",
    "threshold_Pe = 0.09\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_mat =  df_num.corr(method = 'pearson')\n",
    "\n",
    "# Select only those values related to the target\n",
    "coeff_Pe = corr_mat[target].sort_values(ascending = False)[1:] #discard the first one since it is the target itself\n",
    "\n",
    "coeff_Pe = pd.DataFrame(coeff_Pe.values, columns=['Coefficient'], index = coeff_Pe.index )\n",
    "\n",
    "print('Pearsons Correlation')\n",
    "print(abs(coeff_Pe))\n",
    "\n",
    "# Only keep columns whose ABSOLUTE value of the correlation is higer than the threshold\n",
    "cols_Pe = select_columns(abs(coeff_Pe), threshold_Pe) \n",
    "\n",
    "print('\\nColumns to remain in the DF: ', cols_Pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d8187-a898-451c-a8f5-0240f84e48fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cb4ee24-d4d0-448d-8de9-9d0ab1b57fd5",
   "metadata": {},
   "source": [
    "#### Spearman’s Correlation (Nonlinear Correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64d9974c-3104-491c-97c5-7f445b711a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans Correlation\n",
      "             Coefficient\n",
      "Fare            0.172005\n",
      "PassengerId     0.150280\n",
      "SibSp           0.118469\n",
      "Parch           0.046836\n",
      "Pclass          0.001663\n",
      "Age             0.257242\n",
      "\n",
      "Columns to remain in the DF:  ['Fare', 'PassengerId', 'SibSp', 'Age']\n"
     ]
    }
   ],
   "source": [
    "# Define the threshold \n",
    "threshold_Sp = 0.09\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_mat =  df_num.corr(method = 'spearman')\n",
    "\n",
    "# Select only those values related to the target\n",
    "coeff_Sp = corr_mat[target].sort_values(ascending = False)[1:] #discard the first one since it is the target itself\n",
    "\n",
    "coeff_Sp = pd.DataFrame(coeff_Sp.values, columns=['Coefficient'], index = coeff_Sp.index )\n",
    "\n",
    "print('Spearmans Correlation')\n",
    "print(abs(coeff_Sp))\n",
    "\n",
    "# Only keep columns whose ABSOLUTE value of the correlation is higer than the threshold\n",
    "cols_Sp = select_columns(abs(coeff_Sp), threshold_Sp) \n",
    "\n",
    "print('\\nColumns to remain in the DF: ', cols_Sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2cf47-5aff-488d-9879-bc2e93b27d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5a8f52-7b5e-4bfc-905b-09f29ba5d0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf50fc4e-c2e5-4034-8938-7967d8b79ece",
   "metadata": {},
   "source": [
    "### Numerical Input, Categorical Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffab2b47-6929-44ad-9278-636482f82b2a",
   "metadata": {},
   "source": [
    "#### Kendall’s Tau \n",
    "\n",
    "- Kendall’s tau is a measure of the correspondence between two rankings. Values close to 1 indicate strong agreement, and values close to -1 indicate strong disagreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79cd68e5-9d92-4804-86bc-05c068d31def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlaton\n",
      "             Coefficient\n",
      "PassengerId     0.123038\n",
      "Pclass          0.001636\n",
      "Age             0.212465\n",
      "SibSp           0.115947\n",
      "Parch           0.045087\n",
      "Fare            0.141434\n",
      "\n",
      "P-values\n",
      "              p_value\n",
      "PassengerId  0.042622\n",
      "Pclass       0.982105\n",
      "Age          0.000520\n",
      "SibSp        0.109990\n",
      "Parch        0.527487\n",
      "Fare         0.020315\n",
      "\n",
      "Statistically significant Kendall’s Tau\n",
      "             Coefficient\n",
      "PassengerId     0.123038\n",
      "Age             0.212465\n",
      "Fare            0.141434\n",
      "\n",
      "Columns to remain in the DF:  ['Age', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "threshold_Ke = 0.13\n",
    "threshold_Ke_pvalue = 0.05 \n",
    "\n",
    "corr_tau = []\n",
    "p_value = []\n",
    "\n",
    "for i in range(len(X_num.columns)):\n",
    "    tau, p_val = stats.kendalltau(X_num.iloc[:,i], y_cat)\n",
    "    corr_tau.append(abs(tau))\n",
    "    p_value.append(p_val)\n",
    "\n",
    "corr_tau = pd.DataFrame(corr_tau, columns = [\"Coefficient\"], index = X_num.columns)    \n",
    "p_value = pd.DataFrame(p_value, columns = [\"p_value\"], index = X_num.columns) \n",
    "\n",
    "print(\"Correlaton\")\n",
    "print(corr_tau)\n",
    "print(\"\\nP-values\")\n",
    "print(p_value)\n",
    "\n",
    "# Only select the statistically significant measures\n",
    "corr_tau = corr_tau[(p_value[\"p_value\"] < threshold_Ke_pvalue).values] \n",
    "\n",
    "print('\\nStatistically significant Kendall’s Tau')\n",
    "print(corr_tau)\n",
    "\n",
    "# Only keep columns whose ABSOLUTE value of the correlation is higer than the threshold\n",
    "cols_Ke = select_columns(corr_tau, threshold_Ke) \n",
    "\n",
    "print('\\nColumns to remain in the DF: ', cols_Ke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8def64-9132-4e79-83d1-c736811d68a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0b081-669f-4897-b0ff-d295009a9add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25f28b8b-7afe-433d-b205-5d9ad28457eb",
   "metadata": {},
   "source": [
    "### Categorical Input, Numerical Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502d6b23-eb8c-4cfd-8992-1e35105ca88b",
   "metadata": {},
   "source": [
    "#### Kendall’s Tau \n",
    "\n",
    "- Kendall’s tau is a measure of the correspondence between two rankings. Values close to 1 indicate strong agreement, and values close to -1 indicate strong disagreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c73f94f-7907-482a-878c-0056a7600fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlaton\n",
      "          Coefficient\n",
      "Name         0.122497\n",
      "Sex          0.532418\n",
      "Ticket       0.017176\n",
      "Cabin        0.009128\n",
      "Embarked     0.099129\n",
      "\n",
      "P-values\n",
      "               p_value\n",
      "Name      4.354185e-02\n",
      "Sex       6.834238e-13\n",
      "Ticket    7.776211e-01\n",
      "Cabin     8.806636e-01\n",
      "Embarked  1.788363e-01\n",
      "\n",
      "Statistically significant Kendall’s Tau\n",
      "      Coefficient\n",
      "Name     0.122497\n",
      "Sex      0.532418\n",
      "\n",
      "Columns to remain in the DF:  ['Sex']\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "threshold_Ke = 0.13\n",
    "threshold_Ke_pvalue = 0.05 \n",
    "\n",
    "corr_tau = []\n",
    "p_value = []\n",
    "\n",
    "for i in range(len(X_cat.columns)):\n",
    "    tau, p_val = stats.kendalltau(X_cat.iloc[:,i], y)\n",
    "    corr_tau.append(abs(tau))\n",
    "    p_value.append(p_val)\n",
    "\n",
    "corr_tau = pd.DataFrame(corr_tau, columns = [\"Coefficient\"], index = X_cat.columns)    \n",
    "p_value = pd.DataFrame(p_value, columns = [\"p_value\"], index = X_cat.columns) \n",
    "\n",
    "print(\"Correlaton\")\n",
    "print(corr_tau)\n",
    "print(\"\\nP-values\")\n",
    "print(p_value)\n",
    "\n",
    "# Only select the statistically significant measures\n",
    "corr_tau = corr_tau[(p_value[\"p_value\"] < threshold_Ke_pvalue).values] \n",
    "\n",
    "print('\\nStatistically significant Kendall’s Tau')\n",
    "print(corr_tau)\n",
    "\n",
    "# Only keep columns whose ABSOLUTE value of the correlation is higer than the threshold\n",
    "cols_Ke = select_columns(corr_tau, threshold_Ke) \n",
    "\n",
    "print('\\nColumns to remain in the DF: ', cols_Ke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418f38d8-9547-402f-9860-7de49e57acd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20bd05b-5d94-4f68-a44e-31600760853b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42b7251e-1dac-4528-9a43-ed15c3e5ac5f",
   "metadata": {},
   "source": [
    "### Categorial (ANY) Input, Categorical (ANY) Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303497cb-72fb-4c1a-88c0-6792286ff514",
   "metadata": {},
   "source": [
    "#### Chi-Squared Test\n",
    "https://towardsdatascience.com/chi-square-test-for-feature-selection-in-machine-learning-206b1f0b8223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1979785-41b6-4233-91a3-55ecc0e7cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "788be1e9-f9ab-4743-9c85-3d7d42fab441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chi Square values:  [1.25629862e+02 2.49452632e+01 1.96133471e+00 4.50110503e-01\n",
      " 1.32908589e+00 5.37915073e+02 4.83833072e-02 8.06045908e+01\n",
      " 1.83879484e+00 1.21236333e-01 2.42972795e+02]\n",
      "\n",
      " p-values:  [3.70531311e-029 5.89812658e-007 1.61370645e-001 5.02282483e-001\n",
      " 2.48967905e-001 5.35803658e-119 8.25900704e-001 2.75718180e-019\n",
      " 1.75092266e-001 7.27697436e-001 8.84137626e-055]\n",
      "\n",
      "Columns to remain in the DF:  ['Name', 'Sex', 'PassengerId', 'Age', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "# Null hypothesis H0: target is independent from the features.\n",
    "# H0 is REJECTED if p_value <= alpha.\n",
    "\n",
    "alpha = 0.05 #significance level\n",
    "cols_Chi = []\n",
    "\n",
    "# Before performig Chi-Square test we have to make sure data is label encoded.\n",
    "label_encoder = LabelEncoder()\n",
    "X_chi_cat = X_cat.copy()\n",
    "for col in X_chi_cat.columns:\n",
    "    X_chi_cat[col] = label_encoder.fit_transform(X_chi_cat[col])\n",
    "\n",
    "# X_chi is composed of all features. categorical and numeric.    \n",
    "X_chi = pd.concat([X_chi_cat, X_num], axis =1)   \n",
    "\n",
    "#print(X_chi.head(2))\n",
    "\n",
    "# y can be categorical or numeric\n",
    "chi_values, p_values = chi2(X_chi,y) \n",
    "print(\"\\n Chi Square values: \", chi_values)\n",
    "print(\"\\n p-values: \", p_values)\n",
    "\n",
    "# test if target is DEPENDENT of the features. True when p_value <= alpha\n",
    "for i in range(len(p_values)):\n",
    "    if (p_values[i] <= alpha):\n",
    "        cols_Chi.append(X_chi.columns[i])\n",
    "\n",
    "print('\\nColumns to remain in the DF: ', cols_Chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742c6b1-0f1e-4216-b5cf-e0955757f75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fe95ae-ac71-46ee-b450-88eac5780ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e86be0c-8874-42e9-b7c6-22d94821d9a1",
   "metadata": {},
   "source": [
    "## Wrapper\n",
    "\n",
    "- Consider the selection of a set of features as a search problem, where different combinations are prepared, evaluated and compared to other combinations. A predictive model is used to evaluate a combination of features and assign a score based on model accuracy. \n",
    "- Method: Recursive Feature Elimination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec1433-163a-42df-8c5d-371114975bdf",
   "metadata": {},
   "source": [
    "### Numerical Input, Numerical Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aba437-f3f1-4cd0-a1c4-dec20a5b3b6c",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination\n",
    "\n",
    "First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute or callable. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdcd8cbc-2df7-4130-afc0-a429a91c9b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to remain in the DF:  ['PassengerId', 'Age', 'SibSp', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "n_features = int(0.7*len(X_num.columns))\n",
    "\n",
    "if (classification_problem==1):\n",
    "    estimator = DecisionTreeClassifier(min_samples_leaf=4)\n",
    "else:\n",
    "    estimator = DecisionTreeRegressor(min_samples_leaf=4)\n",
    "\n",
    "selector = RFE(estimator, n_features_to_select=n_features, step=1)\n",
    "selector = selector.fit(X_num, y)\n",
    "\n",
    "cols_RFE = list(X_num.columns[selector.support_])\n",
    "\n",
    "print('Columns to remain in the DF: ', cols_RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5740ede-5a97-4716-83fa-21cf2fb90901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81b77ac4-bdd9-4921-892e-6a11a4160c22",
   "metadata": {},
   "source": [
    "## Intrinsic - Feature Importances\n",
    "\n",
    "- There are some machine learning algorithms that perform feature selection automatically as part of learning the model.\n",
    "- This includes algorithms such as penalized regression models like Lasso and decision trees, including ensembles of decision trees like random forest.\n",
    "- Method: Elastic Net, Decision Trees, Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7526db-a979-4284-a59d-fc62b1dd09d3",
   "metadata": {},
   "source": [
    "### Numerical Input, Numerical Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3315c3-fdff-4ef1-9960-522fc58133ea",
   "metadata": {},
   "source": [
    "#### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07da897a-4680-4f4e-a3f5-4972f74f0a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances\n",
      "             Coefficient\n",
      "PassengerId     0.000280\n",
      "Pclass          0.000000\n",
      "Age             0.005441\n",
      "SibSp           0.000000\n",
      "Parch           0.000000\n",
      "Fare            0.000611\n",
      "\n",
      "Columns to remain in the DF:  ['PassengerId', 'Age', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "threshold_El = 0\n",
    "\n",
    "model = ElasticNet()\n",
    "model.fit(X_num, y)\n",
    "\n",
    "feature_importances = pd.DataFrame(np.abs(model.coef_), columns = ['Coefficient'], index = X_num.columns)\n",
    "\n",
    "print('Feature Importances')\n",
    "print(feature_importances)\n",
    "\n",
    "cols_El = select_columns(feature_importances, threshold_El)\n",
    "\n",
    "print('\\nColumns to remain in the DF: ', cols_El)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342926f-4a15-42b1-a0c4-beaf5f045548",
   "metadata": {},
   "source": [
    "#### Decision Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4907b51-ee2b-4c20-a30e-b50d528db892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances\n",
      "             Coefficient\n",
      "PassengerId     0.199157\n",
      "Pclass          0.079733\n",
      "Age             0.383714\n",
      "SibSp           0.114523\n",
      "Parch           0.066708\n",
      "Fare            0.156164\n",
      "\n",
      "Columns to remain in the DF:  ['PassengerId', 'Age', 'SibSp', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "\n",
    "threshold_Tr = 0.11\n",
    "\n",
    "if (classification_problem==1):\n",
    "    model = ExtraTreesClassifier(min_samples_leaf=4)\n",
    "else:\n",
    "    model = ExtraTressRegressor(min_samples_leaf=4)\n",
    "    \n",
    "model.fit(X_num, y)\n",
    "\n",
    "feature_importances = pd.DataFrame(model.feature_importances_, columns = ['Coefficient'], index = X_num.columns)\n",
    "\n",
    "print('Feature Importances')\n",
    "print(feature_importances)\n",
    "\n",
    "\n",
    "cols_Tr = select_columns(feature_importances, threshold_Tr) \n",
    "\n",
    "print('\\nColumns to remain in the DF: ', cols_Tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaf8fa9-bb5d-42d3-bccb-16c5a8d308f5",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "224d7f69-bd40-4fc0-bfba-624e49bfaf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances\n",
      "             Coefficient\n",
      "PassengerId     0.295663\n",
      "Pclass          0.020301\n",
      "Age             0.301414\n",
      "SibSp           0.042231\n",
      "Parch           0.048230\n",
      "Fare            0.292160\n",
      "\n",
      "Columns to remain in the DF:  ['PassengerId', 'Age', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "threshold_RF = 0.11\n",
    "\n",
    "if (classification_problem==1):\n",
    "    model = RandomForestClassifier(n_estimators=200, n_jobs=-1)\n",
    "else:\n",
    "    model = RandomForestRegressor(n_estimators=200, n_jobs=-1)\n",
    "    \n",
    "model.fit(X_num, y)\n",
    "\n",
    "feature_importances = pd.DataFrame(model.feature_importances_, columns = ['Coefficient'], index = X_num.columns)\n",
    "\n",
    "print('Feature Importances')\n",
    "print(feature_importances)\n",
    "\n",
    "\n",
    "cols_RF = select_columns(feature_importances, threshold_RF) \n",
    "\n",
    "print('\\nColumns to remain in the DF: ', cols_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde9080-27c4-4151-b338-8d68f9a7ef3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a96da77c-da15-4d4f-a48e-4a203c457398",
   "metadata": {},
   "source": [
    "# Save the final data frame with the selected columns as a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bf0ff90-efa2-418f-a75e-e60180a06920",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_selected_cols = cols_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17103cbb-5d67-404c-a081-d31b81831cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols_RF].to_json(r'../Data/titanic_train_feature_selection.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a838efa8-0f04-4a09-8727-d48e3cb18ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a34dd-320b-457d-b55a-e1d594c7242e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
